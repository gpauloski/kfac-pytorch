#!/bin/bash

# Sample Slurm job script
#   for TACC Longhorn Nodes
#
#------------------------------------------------------------------------------

#SBATCH -J imgkfc16                 # Job name
#SBATCH -o sbatch_logs/imgnet_kfc16.o%j # Name of stdout output file
#SBATCH -N 16                       # Total # of nodes 
#SBATCH -n 64                       # Total # of mpi tasks
#SBATCH -t 12:00:00                # Run time (hh:mm:ss)
#SBATCH --mail-user=XXX
#SBATCH --mail-type=end            # Send email at begin and end of job
#SBATCH -p v100
#SBATCH -A XXX    # Allocation

mkdir -p sbatch_logs

#source $SCRATCH/anaconda3/bin/activate pytorch1.2

HOSTFILE=/tmp/hostfile

scontrol show hostnames $SLURM_NODELIST > $HOSTFILE
cat $HOSTFILE

mpiexec -hostfile $HOSTFILE -N 1 ./sbatch/cp_imagenet_to_temp.sh

GPU_PER_NODE=4
NODES=$(wc -l < $HOSTFILE)
MASTER_NODE=$(head -n 1 $HOSTFILE)

# We use mpiexec to launch one python -m torch.distributed.launch per node
mpiexec -hostfile $HOSTFILE -N 1 \
  ./sbatch/longhorn/launch_node_torch_imagenet.sh \
    -n $GPU_PER_NODE -N $NODES -m $MASTER_NODE

# -----------------------------------------------------------------------------
